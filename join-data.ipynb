{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-21T13:21:10.722153Z",
     "start_time": "2024-07-21T13:21:10.704178Z"
    }
   },
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "base_file_name = 'cot-zsopt'  # Base file name to match\n",
    "folder_path = 'outputs-cot-zsopt'  # Folder containing the CSV files\n",
    "\n",
    "\n",
    "def collect_csvs():\n",
    "    pattern = re.compile(rf\"^(\\d+)-{re.escape(base_file_name)}\\.csv$\")\n",
    "    csv_files = [file for file in os.listdir(folder_path) if pattern.match(file)]\n",
    "    csv_files.sort(key=lambda x: int(re.findall(r'^\\d+', x)[0]))\n",
    "    return csv_files\n",
    "\n",
    "\n",
    "csv_files = collect_csvs()\n",
    "\n",
    "\n",
    "def combine_csv_files():\n",
    "    df = pd.concat([pd.read_csv(os.path.join(folder_path, file)) for file in csv_files], ignore_index=True)\n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T13:21:18.935648Z",
     "start_time": "2024-07-21T13:21:12.892425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "merged_df = combine_csv_files()\n",
    "merged_df"
   ],
   "id": "e6f53bf4c25125ef",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          Id                                     Original Input  \\\n",
       "0          0  Give some stream of consciousness and then the...   \n",
       "1          1  The student realized that he left his writing ...   \n",
       "2          2  Let's think step by step! How do fungi get nut...   \n",
       "3          3  Denny asked: Test for natural language inferen...   \n",
       "4          4  Please answer the following question by reason...   \n",
       "...      ...                                                ...   \n",
       "95565  95565  Given the sentence \"A low wave is forming in t...   \n",
       "95566  95566  Consider the question. How much 60% of 50 is g...   \n",
       "95567  95567  Use reasoning to lead to the answer of the fol...   \n",
       "95568  95568  Which of these sentences doesn't make sense?\\n...   \n",
       "95569  95569  Yes / no, is the following a verifiable fact?\\...   \n",
       "\n",
       "                                        Translated Input  \\\n",
       "0      යම් ප්‍රවාහයක් ලබා දෙන්න, ඉන්පසු පිළිතුර දෙන්න...   \n",
       "1      ඔහු තම ලේඛන උපකරණය ඔහුගේ අවසාන අධ්‍යයන ස්ථානයේ...   \n",
       "2      පියවරෙන් පියවර සිතමු! දිලීර පෝෂණය ලබා ගන්නේ කෙ...   \n",
       "3      ඩෙනී ඇසුවා: ස්වභාවික භාෂා අනුමාන සඳහා පරීක්ෂණය...   \n",
       "4      කරුණාකර පියවරෙන් පියවර තර්ක කිරීමෙන් පහත ප්‍රශ...   \n",
       "...                                                  ...   \n",
       "95565  \"අළු අහසකට එරෙහිව සාගරයේ පහත් තරංගයක් නිර්මාණය...   \n",
       "95566  ප්රශ්නය සලකා බලන්න. 50 න් 60% 30 න් 50% ට වඩා ...   \n",
       "95567  පහත ප්‍රශ්නයට පිළිතුරු දීමට හේතු දැක්වීම භාවිත...   \n",
       "95568  මේ වාක්‍යවලින් තේරුමක් නැති වාක්‍ය මොනවාද?\\nවි...   \n",
       "95569  ඔව් / නැත, පහත සත්‍ය සත්‍යයක් ද?\\n\"යුනෙස්කෝව බ...   \n",
       "\n",
       "                                         Original Target  \\\n",
       "0      To answer this question, we should know that: ...   \n",
       "1      Classroom is the place of study for students. ...   \n",
       "2      Fungi lack chlorophyll, so they cannot make fo...   \n",
       "3      A snowy mountain is outdoors so if a man is ma...   \n",
       "4      A group of men stand in no particular pattern ...   \n",
       "...                                                  ...   \n",
       "95565  The ocean would not be located in the same pla...   \n",
       "95566        (60/100) * 50 – (50/100) * 30\\n30 - 15 = 15   \n",
       "95567  Car runs at speed that saves time of travellin...   \n",
       "95568  Rats have sharp teeth that can penetrate most ...   \n",
       "95569  UNESCO declared Lake Baikal a World Heritage S...   \n",
       "\n",
       "                                       Translated Target  \n",
       "0      මෙම ප්‍රශ්නයට පිළිතුරු සැපයීම සඳහා, අප දැනගත ය...  \n",
       "1      පන්ති කාමරය යනු සිසුන් සඳහා අධ්‍යයන ස්ථානයයි. ...  \n",
       "2      දිලීර වලට හරිතප්‍රද නොමැති බැවින් ශාක වලට හැකි...  \n",
       "3      හිම සහිත කන්දක් එළිමහනේ, ඒ නිසා මිනිසෙක් හිම ක...  \n",
       "4      මිනිසුන් පිරිසක් කතා නොකර එකිනෙකාගෙන් ඈත් වී ව...  \n",
       "...                                                  ...  \n",
       "95565  පිරිමි ළමයෙකු යහනක වාඩි වී රූපවාහිනිය නරඹන ස්ථ...  \n",
       "95566        (60/100) * 50 - (50/100) * 30\\n30 - 15 = 15  \n",
       "95567  මෝටර් රථය වේගයෙන් ධාවනය වන අතර එමඟින් ගමනේ කාල...  \n",
       "95568  මීයන්ට බොහෝ ද්‍රව්‍ය විනිවිද යාමට හැකි තියුණු ...  \n",
       "95569  යුනෙස්කෝව 1996 දී බයිකල් විල ලෝක උරුමයක් ලෙස ප...  \n",
       "\n",
       "[95570 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Original Input</th>\n",
       "      <th>Translated Input</th>\n",
       "      <th>Original Target</th>\n",
       "      <th>Translated Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Give some stream of consciousness and then the...</td>\n",
       "      <td>යම් ප්‍රවාහයක් ලබා දෙන්න, ඉන්පසු පිළිතුර දෙන්න...</td>\n",
       "      <td>To answer this question, we should know that: ...</td>\n",
       "      <td>මෙම ප්‍රශ්නයට පිළිතුරු සැපයීම සඳහා, අප දැනගත ය...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The student realized that he left his writing ...</td>\n",
       "      <td>ඔහු තම ලේඛන උපකරණය ඔහුගේ අවසාන අධ්‍යයන ස්ථානයේ...</td>\n",
       "      <td>Classroom is the place of study for students. ...</td>\n",
       "      <td>පන්ති කාමරය යනු සිසුන් සඳහා අධ්‍යයන ස්ථානයයි. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Let's think step by step! How do fungi get nut...</td>\n",
       "      <td>පියවරෙන් පියවර සිතමු! දිලීර පෝෂණය ලබා ගන්නේ කෙ...</td>\n",
       "      <td>Fungi lack chlorophyll, so they cannot make fo...</td>\n",
       "      <td>දිලීර වලට හරිතප්‍රද නොමැති බැවින් ශාක වලට හැකි...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Denny asked: Test for natural language inferen...</td>\n",
       "      <td>ඩෙනී ඇසුවා: ස්වභාවික භාෂා අනුමාන සඳහා පරීක්ෂණය...</td>\n",
       "      <td>A snowy mountain is outdoors so if a man is ma...</td>\n",
       "      <td>හිම සහිත කන්දක් එළිමහනේ, ඒ නිසා මිනිසෙක් හිම ක...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Please answer the following question by reason...</td>\n",
       "      <td>කරුණාකර පියවරෙන් පියවර තර්ක කිරීමෙන් පහත ප්‍රශ...</td>\n",
       "      <td>A group of men stand in no particular pattern ...</td>\n",
       "      <td>මිනිසුන් පිරිසක් කතා නොකර එකිනෙකාගෙන් ඈත් වී ව...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95565</th>\n",
       "      <td>95565</td>\n",
       "      <td>Given the sentence \"A low wave is forming in t...</td>\n",
       "      <td>\"අළු අහසකට එරෙහිව සාගරයේ පහත් තරංගයක් නිර්මාණය...</td>\n",
       "      <td>The ocean would not be located in the same pla...</td>\n",
       "      <td>පිරිමි ළමයෙකු යහනක වාඩි වී රූපවාහිනිය නරඹන ස්ථ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95566</th>\n",
       "      <td>95566</td>\n",
       "      <td>Consider the question. How much 60% of 50 is g...</td>\n",
       "      <td>ප්රශ්නය සලකා බලන්න. 50 න් 60% 30 න් 50% ට වඩා ...</td>\n",
       "      <td>(60/100) * 50 – (50/100) * 30\\n30 - 15 = 15</td>\n",
       "      <td>(60/100) * 50 - (50/100) * 30\\n30 - 15 = 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95567</th>\n",
       "      <td>95567</td>\n",
       "      <td>Use reasoning to lead to the answer of the fol...</td>\n",
       "      <td>පහත ප්‍රශ්නයට පිළිතුරු දීමට හේතු දැක්වීම භාවිත...</td>\n",
       "      <td>Car runs at speed that saves time of travellin...</td>\n",
       "      <td>මෝටර් රථය වේගයෙන් ධාවනය වන අතර එමඟින් ගමනේ කාල...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95568</th>\n",
       "      <td>95568</td>\n",
       "      <td>Which of these sentences doesn't make sense?\\n...</td>\n",
       "      <td>මේ වාක්‍යවලින් තේරුමක් නැති වාක්‍ය මොනවාද?\\nවි...</td>\n",
       "      <td>Rats have sharp teeth that can penetrate most ...</td>\n",
       "      <td>මීයන්ට බොහෝ ද්‍රව්‍ය විනිවිද යාමට හැකි තියුණු ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95569</th>\n",
       "      <td>95569</td>\n",
       "      <td>Yes / no, is the following a verifiable fact?\\...</td>\n",
       "      <td>ඔව් / නැත, පහත සත්‍ය සත්‍යයක් ද?\\n\"යුනෙස්කෝව බ...</td>\n",
       "      <td>UNESCO declared Lake Baikal a World Heritage S...</td>\n",
       "      <td>යුනෙස්කෝව 1996 දී බයිකල් විල ලෝක උරුමයක් ලෙස ප...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95570 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T13:21:25.908165Z",
     "start_time": "2024-07-21T13:21:25.367480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load Original Dataset to Verify\n",
    "import utils\n",
    "\n",
    "folder_path = 'cot-zsopt'  # Folder containing the original dataset\n",
    "dataset = utils.load_dataset(folder_path)\n",
    "\n",
    "len(merged_df), len(dataset)"
   ],
   "id": "efb8ea9d8d5f1268",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95570, 95570)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T13:21:30.569618Z",
     "start_time": "2024-07-21T13:21:30.498711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_row_continuity(df: pd.DataFrame, id_column: str = 'Id') -> bool:\n",
    "    expected_ids = set(df[id_column])\n",
    "    actual_ids = set(range(len(df)))\n",
    "\n",
    "    missing_ids = expected_ids - actual_ids\n",
    "    extra_ids = actual_ids - expected_ids\n",
    "\n",
    "    if missing_ids:\n",
    "        print(f\"Missing IDs: {sorted(missing_ids)}\")\n",
    "\n",
    "    if extra_ids:\n",
    "        print(f\"Extra IDs: {sorted(extra_ids)}\")\n",
    "\n",
    "    if missing_ids or extra_ids:\n",
    "        return False\n",
    "    else:\n",
    "        print(\"All rows are present and in order.\")\n",
    "        return True\n",
    "\n",
    "\n",
    "db_continuity = check_row_continuity(merged_df)"
   ],
   "id": "d6628ba16d717b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All rows are present and in order.\n"
     ]
    }
   ],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T13:24:14.043310Z",
     "start_time": "2024-07-21T13:24:11.686099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "parquet_file_name = \"cot-zsopt\"  # Name of the parquet file to save\n",
    "\n",
    "if not db_continuity or len(merged_df) != len(dataset):\n",
    "    raise ValueError(\"Data continuity is not maintained.\")\n",
    "\n",
    "updated_df = merged_df.drop(columns='Id')\n",
    "\n",
    "\n",
    "def save_as_parquet(df: pd.DataFrame, file_name: str) -> str:\n",
    "    parquet_path = f\"translated_datasets/{file_name}.parquet\"\n",
    "    if os.path.exists(parquet_path):\n",
    "        print(f\"File {parquet_path} already exists. Not overwriting.\")\n",
    "        return parquet_path\n",
    "    df.to_parquet(parquet_path, index=False)\n",
    "    print(f\"Data saved as {parquet_path}\")\n",
    "    return parquet_path\n",
    "\n",
    "\n",
    "parquet_path = save_as_parquet(updated_df, parquet_file_name)"
   ],
   "id": "31fe38ed926db9d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved as translated_datasets/cot-zsopt.parquet\n"
     ]
    }
   ],
   "execution_count": 123
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T13:37:41.683152Z",
     "start_time": "2024-07-21T13:37:22.503485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from huggingface_hub import HfFolder\n",
    "from pandas import DataFrame\n",
    "from huggingface_hub.utils import RepositoryNotFoundError\n",
    "import datasets as hf_datasets\n",
    "\n",
    "if not db_continuity or len(merged_df) != len(dataset):\n",
    "    raise ValueError(\"Data continuity is not maintained.\")\n",
    "\n",
    "\n",
    "def upload_subset_to_huggingface(df: DataFrame, repo_id: str, subset_name: str):\n",
    "    try:\n",
    "        print(f\"Creating dataset from DataFrame with {len(df)} rows.\")\n",
    "        dataset = hf_datasets.Dataset.from_pandas(df)\n",
    "\n",
    "        print(f\"Creating DatasetDict with subset '{subset_name}'\")\n",
    "        dataset_dict = hf_datasets.DatasetDict({\n",
    "            f\"subset_{subset_name}\": dataset\n",
    "        })\n",
    "\n",
    "        print(f\"Pushing to Hugging Face Hub: {repo_id}\")\n",
    "        dataset_dict.push_to_hub(repo_id, private=False, token=HfFolder.get_token())\n",
    "\n",
    "        print(f\"File uploaded successfully to {repo_id}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "repo_id = \"0xAIT/sinhala-flan\"\n",
    "subset_name = \"cot_zsopt\"\n",
    "upload_subset_to_huggingface(updated_df, repo_id, subset_name)"
   ],
   "id": "32f5b01df129318a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset from DataFrame with 95570 rows.\n",
      "Creating DatasetDict with subset 'cot_zsopt'\n",
      "Pushing to Hugging Face Hub: 0xAIT/sinhala-flan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b3d8b80ae00a4d8eb495a2f4e948fd3a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/96 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1ef3a25993846e2b0e60dc75a5cb54e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/462 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5137fee254344fe79243c47fd7c4fa08"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded successfully to 0xAIT/sinhala-flan\n"
     ]
    }
   ],
   "execution_count": 124
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Verify Token Access\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "\n",
    "def verify_repository(repo_id: str, token: str):\n",
    "    api = HfApi()\n",
    "    try:\n",
    "        repo_info = api.repo_info(repo_id, token=token, repo_type=\"dataset\")\n",
    "        print(f\"Repository {repo_id} exists and is accessible.\")\n",
    "    except RepositoryNotFoundError:\n",
    "        print(f\"Repository {repo_id} does not exist. Please create it or check the repository ID.\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while verifying the repository: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "verify_repository(repo_id, HfFolder.get_token())"
   ],
   "id": "d218b39a8325bcad",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
